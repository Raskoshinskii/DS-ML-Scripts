{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuning\n",
    "The are several main techniques thah can be used for hyperparameters tunning\n",
    "\n",
    "### GridSearchCV\n",
    "Performs an exhaustive search over the specified range of hyperparameters (grid). For this method you need to specify every single value for each parameter (which can be tricky, especially for the continuous parameters) that you want your model to try.\n",
    "\n",
    "**The main disadvantages:**\n",
    "- If searching space is large, it takes forever\n",
    "- Discrete set of parameters (if optimum value is 150 but the range is `[100, 200]`, the optimum won't be found)\n",
    "\n",
    "### Randomized Search CV\n",
    "Doesn’t set up a grid of hyperparameter values. Instead, we have to specify a distribution for each hyperparameter we want to tune. Randomized Search CV then sample values from these distributions and selects their random combinations. \n",
    "\n",
    "But still the optimum set of hyperparameters can be missed due to the randomness of the algorithm.\n",
    "\n",
    "### Bayesian Methods\n",
    "More advanced approaches are using the history of past trials to select hyperparameters for each trial in an informed manner. This often results in the faster hyperparameter tuning process and more accurate resulting models. There are several modules that allow implementing this algorithm:\n",
    "- Hyperopt\n",
    "- Optuna \n",
    "\n",
    "### Hyperopt Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import tpe, hp, fmin, space_eval, Trials\n",
    "from hyperopt.pyll.stochastic import sample as ho_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHyperparametersHyperopt:\n",
    "    \"\"\"\n",
    "    Class for hyperparameters optimizations using Hyperopt library\n",
    "    CV type: cross_val_score\n",
    "    \n",
    "    NOTE: Delete minus in _objective for return statement when using non regression metrics \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, X_train, y_train, params_space, n_trials, cv_metric, cv_type, fit_params=None, opt_algo=tpe.suggest, seed=23):\n",
    "        \"\"\"\n",
    "        model: callable\n",
    "        \n",
    "        X_train/y_train: DataFrame\n",
    "        \n",
    "        params_space: dict\n",
    "            Hyperparameters space defined according to Hyperopt documentation \n",
    "            \n",
    "        n_trials: int\n",
    "            Number of iterations to find optimal hyperparameters\n",
    "            \n",
    "        cv_metric: str\n",
    "            Name for the metric to be used according (sklearn metrics)\n",
    "            \n",
    "        cv_type: callable\n",
    "            Cross validation type\n",
    "            \n",
    "        fit_params: dict \n",
    "            Additional parameters for the model\n",
    "            \n",
    "        opt_algo: callable\n",
    "            Type of an algorithm that searches in a hyperparameters space \n",
    "            \n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.params_space = params_space\n",
    "        self.n_trials = n_trials\n",
    "        self.cv_metric = cv_metric\n",
    "        self.cv_type = cv_type\n",
    "        self.fit_params = fit_params\n",
    "        self.opt_algo = opt_algo\n",
    "        self.seed = seed\n",
    "        self.trials = Trials()\n",
    "        \n",
    "    def _objective(self):\n",
    "        \"\"\"\n",
    "        Defines the objective function\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        self.model.set_params(**self.params_space)\n",
    "        \n",
    "        cv_score = cross_val_score(self.model,\n",
    "                                   self.X_train,\n",
    "                                   self.y_train,\n",
    "                                   scoring=self.cv_metric,\n",
    "                                   cv=self.cv_type,\n",
    "                                   error_score='reaise',\n",
    "                                   fit_params=self.fit_params,\n",
    "                                   n_jobs=-1)\n",
    "        \n",
    "        return -cv_score.mean()\n",
    "        \n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        Find optimal hyperparameters by minimizing the objective function\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        return fmin(fn=self._objective,\n",
    "                    space=self.params_space,\n",
    "                    algo=self.opt_algo,\n",
    "                    max_evals=self.n_trials,\n",
    "                    trials=self.trials,\n",
    "                    rstate=np.random.RandomState(self.seed))\n",
    "    \n",
    "# model_hyperparameters = ModelHyperparameters(model=model_name, X_train=X_train, y_train=y_train,\n",
    "#                                              params_space=params_space, n_trials=50, cv_metric='roc_auc',\n",
    "#                                              cv_type=StratifiedKFold(shuffle=True, random_state=SEED))\n",
    "\n",
    "# best_params = model_hyperparameters.optimize()\n",
    "\n",
    "# For better found parameters retrieval use space_eval\n",
    "# space_eval(params_space, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for hyperparameters space - GradientBoostingClassifier\n",
    "params_space = {\n",
    "    'model__learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(0.5)),\n",
    "    'model__n_estimators': ho_scope.int(hp.quniform('n_estimators', 50, 500, 1)),\n",
    "    'model__criterion': hp.choice('criterion', ['friedman_mse', 'mse']), # don't use mae\n",
    "    'model__min_samples_split': hp.loguniform('min_samples_split', np.log(0.1), np.log(1)),\n",
    "    'model__max_depth':  ho_scope.int(hp.quniform('max_depth', 1, 8, 1)),\n",
    "    'model__max_features': ho_scope.int(hp.quniform('max_features', 1, x_train.shape[1], 1)),\n",
    "    'model__random_state': SEED\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna \n",
    "from optuna import samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHyperparametersOptuna:\n",
    "    \"\"\"\n",
    "    Class for hyperparameters optimizations using Hyperopt library\n",
    "    CV type: cross_val_score\n",
    "    \n",
    "    NOTE: Delete minus in _objective for return statement when using non regression metrics \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, X_train, y_train, params_space, n_trials, cv_metric, cv_type, opt_algo='tpe', direction='maximize', seed=23):\n",
    "        \"\"\"\n",
    "        model: callable\n",
    "        \n",
    "        X_train/y_train: DataFrame\n",
    "        \n",
    "        params_space: dict\n",
    "            Hyperparameters Space defined according to the Optuna documentation\n",
    "        \n",
    "        n_trials: int\n",
    "            Number of iterations to find optimal hyperparameters\n",
    "            \n",
    "        cv_metric: str\n",
    "            Name for the metric to be used according (sklearn metrics)\n",
    "            \n",
    "        cv_type: callable\n",
    "            Cross validation type\n",
    "            \n",
    "        opt_algo: str\n",
    "            Type of an optimization algorithm\n",
    "            \n",
    "        direction: str\n",
    "            Wether to maximize or minimize the \n",
    "            \n",
    "        opt_algo: callable\n",
    "            Type of an algorithm that searches in a hyperparameters space \n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.params_space = params_space\n",
    "        self.n_trials = n_trials\n",
    "        self.cv_metric = cv_metric\n",
    "        self.cv_type = cv_type\n",
    "        self.direction = direction\n",
    "        self.seed = seed\n",
    "        self.study = None\n",
    "        \n",
    "        if opt_algo == 'tpe':\n",
    "            self.opt_algo = samplers.TPESampler(self.seed)\n",
    "        \n",
    "        \n",
    "    def _objective(self, trial):\n",
    "        \"\"\"\n",
    "        Defines the objective function\n",
    "        \n",
    "        \"\"\"\n",
    "            \n",
    "        self.model.set_params(**self.params_space) \n",
    "        \n",
    "        cv_score = cross_val_score(self.model, self.X_train, self.y_train,\n",
    "                                   scoring=self.cv_metric, cv=self.cv_type, n_jobs=-1)\n",
    "        return cv_score.mean()\n",
    "    \n",
    "    def optimize(self):\n",
    "        self.study = optuna.create_study(sampler=self.opt_algo, direction=self.direction)\n",
    "        self.study.optimize(self._objective, n_trials=self.n_trials)\n",
    "        \n",
    "        \n",
    "# model_hyperparameters = ModelHyperparameters(model=model_name, X_train=X_train, y_train=y_train, params_space=params_space,\n",
    "#                                              n_trials=50, cv_metric='roc_auc',\n",
    "#                                              cv_type=StratifiedKFold(shuffle=True, random_state=SEED))\n",
    "\n",
    "# model_hyperparameters.optimize()\n",
    "# model_hyperparameters.study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV and RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV , RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHyperparametersGridSearchCV:\n",
    "    \"\"\"\n",
    "    Class for hyperparameters optimizations using GridSearchCV\n",
    "    CV type: cross_val_score\n",
    "    \n",
    "    NOTE: Delete minus in _objective for return statement when using non regression metrics \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grid_type, model, X_train, y_train, params_space, cv_metric, cv_type, seed=23):\n",
    "        \"\"\"\n",
    "        grid_type: callable\n",
    "            GridSearchCV or RandomizedSearchCV\n",
    "        \n",
    "        model: callable\n",
    "        \n",
    "        X_train/y_train: DataFrame\n",
    "        \n",
    "        params_space: dict\n",
    "            Hyperparameters Space defined according to the Optuna documentation\n",
    "        \n",
    "        cv_metric: str or dict (google: \"Running GridSearchCV using multiple evaluation metrics\") \n",
    "            Name for the metric to be used according (sklearn metrics)\n",
    "            \n",
    "        cv_type: callable\n",
    "            Cross validation type\n",
    "\n",
    "        \"\"\"\n",
    "        self.grid_type = grid_type\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.params_space = params_space\n",
    "        self.cv_metric = cv_metric\n",
    "        self.cv_type = cv_type\n",
    "        self.seed = seed\n",
    "        \n",
    "    def optimize(self, n_iter):\n",
    "        class_name = self.grid_type.__name__\n",
    "        \n",
    "        if class_name.lower().startswith('rand'):\n",
    "            model = self.grid_type(estimator=elf.model,\n",
    "                                   param_distributions=self.params_space,\n",
    "                                   scoring=self.cv_metric,\n",
    "                                   cv=self.cv_type,\n",
    "                                   n_iter=n_iter,\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=self.seed)\n",
    "        else:\n",
    "            model = self.grid_type(estimator=self.model,\n",
    "                                   param_grid=self.params_space,\n",
    "                                   scoring=self.cv_metric,\n",
    "                                   cv=self.cv_type,\n",
    "                                   n_jobs=-1)\n",
    "        \n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        return model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некторые приближения гиперпараметров для моделей \n",
    "\n",
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "params = {\n",
    "    'learning_rate': trial.suggest_uniform('learning_rate', 0.001, 0.5),\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 40, 1000),\n",
    "    'criterion': trial.suggest_categorical('criterion', ['friedman_mse', 'mse']),\n",
    "    'min_samples_split': trial.suggest_uniform('learning_rate', 0.1, 1),\n",
    "    'min_samples_leaf': trial.suggest_uniform('learning_rate', 0.1, 1),\n",
    "    'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "    'max_features': trial.suggest_int('max_features', 1, x_train.shape[1])\n",
    "}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna\n",
    "from xgboost import XGBClassifier\n",
    "xgboost_model = XGBClassifier(**params)\n",
    "\n",
    "params = {\n",
    "    'n_estimators': trial.suggest_int('n_estimators', 40, 600),\n",
    "    'max_depth': trial.suggest_int('max_depth', 2, 20),\n",
    "    'min_child_weight': trial.suggest_int('min_child_weight', 2, 20),\n",
    "    'learning_rate': trial.suggest_uniform('learning_rate', 0.001, 0.5),\n",
    "    'base_score': trial.suggest_uniform('base_score', 0.01, 1),\n",
    "    'subsample': trial.suggest_uniform('subsample', 0.50, 1),\n",
    "    'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.50, 1),\n",
    "    'colsample_bynode': trial.suggest_uniform('colsample_bytree', 0.50, 1),\n",
    "    'colsample_bylevel': trial.suggest_uniform('colsample_bytree', 0.50, 1),\n",
    "    'gamma': trial.suggest_int('gamma', 0, 10),\n",
    "    'tree_method': 'gpu_hist',  \n",
    "    'objective': 'binary:logistic'\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
