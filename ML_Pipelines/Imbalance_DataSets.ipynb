{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Tracks the quality depending on the weights set for observations  \n",
    "def show_model_cvs_class_weights(model, x_train, y_train, cv_type, metrics, weights=np.linspace(0.05, 0.95, 20)):\n",
    "    res_df = pd.DataFrame()\n",
    "    \n",
    "    for weight in log_progress(weights):\n",
    "        cv_results = cross_validate(model,\n",
    "                                    X=x_train,\n",
    "                                    y=y_train, \n",
    "                                    cv=cv_type,\n",
    "                                    scoring=metrics,\n",
    "                                    error_score='raise',\n",
    "                                    n_jobs=-1,\n",
    "                                    fit_params={'model__sample_weight': y_train.apply(lambda x: weight if x == 1.0 else 1 - weight)})\n",
    "           \n",
    "        cv_results['Min_Class_Weight'] = weight \n",
    "        res_df = res_df.append(pd.DataFrame(pd.DataFrame(cv_results).mean()).iloc[2:, :].T)\n",
    "    \n",
    "    return res_df\n",
    "\n",
    "# %%time\n",
    "# weights_cv_results = show_model_cvs_class_weights(\n",
    "#     model=model_pipeline,\n",
    "#     x_train=x_train,\n",
    "#     y_train=y_train,\n",
    "#     cv_type=StratifiedKFold(shuffle=True, random_state=SEED),\n",
    "#     metrics=['precision', 'recall', 'f1', 'roc_auc'],\n",
    "#     weights=np.linspace(0.05, 0.95, 20)\n",
    "# )\n",
    "\n",
    "# weights_cv_results = weights_cv_results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Over/UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем функцию over/under sampling \n",
    "def show_model_cvs_random_sampling(model, x_train, y_train, cv_type, metrics,\n",
    "                                   sample_iters=20, sampling_type='under',\n",
    "                                   target_labels=[-1, 1], random_state=SEED):\n",
    "    res_df = pd.DataFrame()\n",
    "    \n",
    "    # Определяем число объектов мажоритарного и минорного классов\n",
    "    maj_class_size, min_class_size = y_train.value_counts()\n",
    "    \n",
    "    # Поделим данный интервал на необходимое количество значений\n",
    "    n_samples = np.linspace(min_class_size, maj_class_size, sample_iters)\n",
    "    n_samples = np.floor(n_samples).astype('int') # Получим целочисленные значения\n",
    "    \n",
    "    # Разделяем выборки на классы\n",
    "    x_train[y_train.name] = y_train\n",
    "    \n",
    "    x_train_pos_class = x_train[x_train[y_train.name] == max(target_labels)] \n",
    "    x_train_neg_class = x_train[x_train[y_train.name] == min(target_labels)]\n",
    "    \n",
    "    x_train.drop(y_train.name, axis=1, inplace=True) # Чтобы после завершения, таргет не присутствовал в обучении\n",
    "    \n",
    "    if sampling_type == 'under':\n",
    "        for sample_size in log_progress(n_samples):\n",
    "            # Сэмлируем необходимое число объектов мажоритарного класса\n",
    "            x_train_neg_under = x_train_neg_class.sample(sample_size, random_state=random_state)\n",
    "\n",
    "            # Cоздаем обучающую выборку\n",
    "            x_train_under = pd.concat([x_train_neg_under, x_train_pos_class], axis=0)\n",
    "            y_train = x_train_under[y_train.name]\n",
    "\n",
    "            # Удаляем целевой класс из обучения\n",
    "            x_train_under.drop(y_train.name, axis=1, inplace=True)\n",
    "\n",
    "            # Кросс-валидируемся\n",
    "            cv_results = cross_validate(model, X=x_train_under, y=y_train, \n",
    "                                        cv=cv_type, scoring=metrics, error_score='raise', n_jobs=-1)\n",
    "\n",
    "            cv_results['Sample_Size'] = sample_size\n",
    "            res_df = res_df.append(pd.DataFrame(pd.DataFrame(cv_results).mean()).iloc[2:, :].T)\n",
    "            \n",
    "        return res_df\n",
    "    \n",
    "    else:\n",
    "        for sample_size in log_progress(n_samples):\n",
    "            # Сэмлируем необходимое число объектов минорного класса\n",
    "            x_train_pos_over = x_train_pos_class.sample(sample_size, replace=True, random_state=random_state)\n",
    "            \n",
    "            # Cоздаем обучающую выборку\n",
    "            x_train_over = pd.concat([x_train_neg_class, x_train_pos_over], axis=0)\n",
    "            y_train = x_train_over[y_train.name]\n",
    "        \n",
    "            # Удаляем целевой класс из обучения\n",
    "            x_train_over.drop(y_train.name, axis=1, inplace=True)\n",
    "        \n",
    "            # Кросс-валидируемся\n",
    "            cv_results = cross_validate(model, X=x_train_over, y=y_train, \n",
    "                                        cv=cv_type, scoring=metrics, error_score='raise', n_jobs=-1)\n",
    "        \n",
    "            cv_results['Sample_Size'] = sample_size\n",
    "            res_df = res_df.append(pd.DataFrame(pd.DataFrame(cv_results).mean()).iloc[2:, :].T)\n",
    "            \n",
    "        return res_df\n",
    "    \n",
    "    \n",
    "# %%time \n",
    "# under_cv_results = show_model_cvs_random_sampling(model=model_pipeline,\n",
    "#                                                   x_train=x_train,\n",
    "#                                                   y_train=y_train,\n",
    "#                                                   cv_type=StratifiedKFold(shuffle=True, random_state=SEED),\n",
    "#                                                   metrics=['precision', 'recall', 'f1', 'roc_auc'],\n",
    "#                                                   sampling_type='under',\n",
    "#                                                   sample_iters=20)\n",
    "\n",
    "# under_cv_results = under_cv_results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "# # Переопределяем Pipeline\n",
    "# model_pipeline = make_pipe(cat_bin_columns=cat_features.columns,\n",
    "#                            num_columns=num_features.columns,\n",
    "#                            model=GradientBoostingClassifier(random_state=SEED),\n",
    "#                            cat_bin_imputer=SimpleImputer(strategy='constant', fill_value='unknown'),\n",
    "#                            cat_bin_encoder=OneHotEncoder(sparse=True, handle_unknown='ignore'),\n",
    "#                            num_imputer=SimpleImputer(strategy='mean'),\n",
    "#                            num_scaler=StandardScaler())\n",
    "\n",
    "# # Добавим этап downsampling в Pipeline\n",
    "# model_pipeline.steps.insert(1, ('downsampling', TomekLinks(sampling_strategy='majority', n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
