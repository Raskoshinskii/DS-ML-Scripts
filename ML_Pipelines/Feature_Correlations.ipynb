{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V-Crammer Correlation\n",
    "Correlation between categorical features and a binary target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "def calculate_crammer_coef_corr(confusion_matrix):\n",
    "    chi2_val = sts.chi2_contingency(confusion_matrix)[0]\n",
    "    n_observations = confusion_matrix.sum().sum()\n",
    "    phi_val = chi2_val/n_observations\n",
    "    n_rows, n_colmns = confusion_matrix.shape\n",
    "    \n",
    "    # Корректировка значений phi_val, n_rows и n_colmns\n",
    "    phi_val_corr = max(0, phi_val - ((n_colmns-1)*(n_rows-1))/(n_observations-1)) \n",
    "    n_rows_corr = n_rows - ((n_rows-1)**2)/(n_observations-1)\n",
    "    n_colmns_corr = n_colmns - ((n_colmns-1)**2)/(n_observations-1)\n",
    "    return np.sqrt(phi_val_corr / min( (n_colmns_corr-1), (n_rows_corr-1)))\n",
    "\n",
    "# Option 2 (preffered)\n",
    "def calculate_crammer_coef(feature_df, target, correction=True, return_p_value=True, ascending=False):\n",
    "    \"\"\"\n",
    "    feature_df: DataFrame\n",
    "        Main DataFrame with only categorical features and without target feature\n",
    "    target: Series \n",
    "        Target feature \n",
    "        \n",
    "    If return_p_value = True return a tuple (Feature Name, p-value, V-Crammer Value)\n",
    "    Otherwise the tuple (Feature Name, V-Crammer Value)\n",
    "    \n",
    "    If ratio doesn't meet the conditions, the feature will be excluded from calculation\n",
    "    \n",
    "    \"\"\"\n",
    "    crammer_corrs = [] # for storing the calculated correlations\n",
    "    \n",
    "    for feature in feature_df.columns:\n",
    "        confusion_matrix = pd.crosstab(feature_df[feature], target)\n",
    "        n_observations = feature_df[feature].shape[0]\n",
    "        n_rows, n_colmns = confusion_matrix.shape\n",
    "        \n",
    "         # Confusion Matrix must follow some conditions before applying the method\n",
    "        ratio = (np.sum((confusion_matrix.loc[:, -1] < 5)) + np.sum((confusion_matrix.loc[:, -1] < 5)))/confusion_matrix.size\n",
    "        \n",
    "        if ratio <= 0.2:\n",
    "            # p-values option\n",
    "            if return_p_value:\n",
    "                chi2_res = sts.chi2_contingency(confusion_matrix, correction=correction)\n",
    "                crammer_corrs.append((feature_df[feature].name, chi2_res[1], np.sqrt(chi2_res[0]/(n_observations*(min(n_rows, n_colmns)-1)))))\n",
    "            else:\n",
    "                chi2_val = sts.chi2_contingency(confusion_matrix, correction=correction)[0]\n",
    "                crammer_corrs.append((feature_df[feature].name, np.sqrt(chi2_val/(n_observations*(min(n_rows, n_colmns)-1)))))\n",
    "    \n",
    "    return pd.DataFrame(crammer_corrs, columns=['Feature', 'p-value', 'V_Crammer_Value']).sort_values(by='V_Crammer_Value', ascending=ascending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Expectation Difference\n",
    "Correlation between numerical features and a binary target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def math_exp_differences(feat_df, target, ascending=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    feat_df: DataFrame\n",
    "        Main DataFrame with only numerical features and without target feature\n",
    "        \n",
    "    target: Series\n",
    "        Target feature\n",
    "        \n",
    "    ascending: Ascending type\n",
    "    \n",
    "    \"\"\"\n",
    "    main_df = pd.concat([feat_df, target], axis=1) # for combining features with the target\n",
    "    main_df = main_df.dropna() # DataFrame must be without NaN values because it affects the result\n",
    "    \n",
    "    \n",
    "    mat_exp_diff = [] # for storing the results\n",
    "    \n",
    "    for feature in feat_df.columns:\n",
    "        group_means = main_df[[feature, target.name]].groupby(by=target.name).mean()\n",
    "        means_diff = group_means.iloc[0, 0] - group_means.iloc[1, 0]\n",
    "        \n",
    "        mat_exp_diff.append(means_diff)\n",
    "        \n",
    "    df = abs(pd.DataFrame({'Corr_ME_diffs':mat_exp_diff}, index=feat_df.columns))\n",
    "\n",
    "    return df.sort_values(by='Corr_ME_diffs', ascending=ascending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi2\n",
    "Features must not have NaN and must be scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# feat_selector = SelectKBest(score_func=chi2, k=5)\n",
    "# feat_selector.fit(num_feat_testing, y_train)\n",
    "\n",
    "# num_feat_chi_2_df = pd.DataFrame({'chi_2_score': feat_selector.scores_,\n",
    "#                                   'p_value': feat_selector.pvalues_}, index=num_features.columns)\n",
    "\n",
    "# num_feat_chi_2_df = num_feat_chi_2_df.sort_values(['chi_2_score'] , ascending=False)\n",
    "# num_feat_chi_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
